Artificial Intelligence (AI) has been at the forefront of technological innovation in recent years, transforming various aspects of our lives. Language models like GPT-3 have had a profound impact on society, even aiding in healthcare and education. Despite their undeniable benefits, however, Large Language Models (LLMs) also raise significant concerns and negatives for society in the form of bias. This being said, I believe that the next big advancement in AI isn't another product but rather the industry pushing AI into all places applicable regardless of its possible ramifications.

In Section SQ10 of “Gathering Strength, Gathering Storms:”, we learn that “Automated decision-making may produce skewed results that replicate and amplify existing biases.” (SQ10, 2021) At first, this may be confusing because artificial intelligence at its core isn't a human but rather a computer so bias would be impossible to generate. But when you dig deeper we learn that these algorithms are trained based on data that is, in fact, biased. We learn from a study looking at where more crime may occur that AI “...disproportionately projected crimes in areas with higher populations of non-white and low-income residents…” (SQ10, 2021) Directly showing discrimination in what should have been a completely fair process. This shows how AI may actually not be applicable to all cases.

In section 9 of “Sparks of Artificial General Intelligence: Early experiments with GPT-4” we learn about how GPT-4 and its successors have the potential for significant societal impact. Section 9 offers a breakdown of how GPT-4 biases their language when using pronouns. When referring to nannies we learn that the LLM will use she/her 99% of the time while only 95% of nannies are female. We also learn that while 78% of software engineers are male GPT-4 will use he/him 98% of the time. (pg.87,2021) This shows, again, how LLMs will continue to regurgitate biases even when developed in a way to be as rational as possible. 

Additionally, in “ChatGPT for good? On opportunities and challenges of large language models for education” we learn about how Large Language Models will continuously bring up biases. We learn how, “if a model is trained on data that is biased towards certain groups of people, it may produce results that are unfair or discriminatory towards those groups”(4.2, 2023) The paper continues to elaborate on this idea by speaking about how if these LLM have, “local knowledge about minorities such as small ethnic groups or cultures [bias] can fade into the background”(4.2, 2023) of the information being given out.

AI’s imposition on our society is real. We are seeing it today when insurance companies quote consumers. At its core (data), AI is full of bias just like the reality of our society. So with AI being trained with something we as a society find disgusting, it's unfair to impose this wherever profitable. So, for now, we may be content with websites like chat.openai.com, the second we start implementing AI into infrastructure core to our society, it will be nothing but devastating.
